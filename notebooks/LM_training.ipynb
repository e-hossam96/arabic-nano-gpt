{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a811925-79f5-498c-a1de-8b25942f9a39",
   "metadata": {},
   "source": [
    "# GPT2 Language Model Training\n",
    "\n",
    "In this notebook, we will train our model on sample data to estimate its runnig time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042b5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629bdfdd-b6a3-4a55-8d92-4fb5c3cc6398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import huggingface_hub\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025c72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7de2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='notebook', style='dark')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcf8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "transformers.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb8f848-496d-4de4-b219-800768ca964d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = Path('../data/wikipeda.csv')\n",
    "tokenizer_pah = Path('../models/nano-gpt-tokenizer/')\n",
    "model_ckpt = 'openai-community/gpt2'\n",
    "model_name = 'arabic-nano-gpt'\n",
    "model_path = Path(f'../models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27da62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">..<span style=\"color: #800080; text-decoration-color: #800080\">/models/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">arabic-nano-gpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "..\u001b[35m/models/\u001b[0m\u001b[95marabic-nano-gpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d47fcd-7209-41f1-bd5b-1e1ccc36c016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb configs\n",
    "PROJECT_NAME = 'Arabic-Nano-GPT'\n",
    "JOB_TYPE = 'LM-Modeling'\n",
    "TAGS = ['MOdeling', 'Transformers', 'GPT2', 'Language-Modeling', 'Arabic']\n",
    "NOTES = 'LM Training on Arabic Data using Nano GPT2 Model Architecture'\n",
    "RUN_NAME = 'Overfitting-Small-Batch'\n",
    "config = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc5b437-b659-4f0b-bbda-ca6977bb64c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me_hossam96\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "wandb.login()\n",
    "huggingface_hub.login(token=os.getenv('HF_TOKEN'),\n",
    "      add_to_git_credential=True, write_permission=True)  # HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007ca13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "    features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    num_rows: \u001b[1;36m500\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = load_dataset(\n",
    "    'csv', data_files='../data/wikipeda.csv', split='train[:500]')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ca1a0d-e629-4a73-a8d3-5f1e75ed6a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetDict</span><span style=\"font-weight: bold\">({</span>\n",
       "    train: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    test: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDatasetDict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    train: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m450\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    test: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m50\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(train_size=0.9, seed=seed)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d968273f-a57d-4da1-8be4-87ed0967d060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetDict</span><span style=\"font-weight: bold\">({</span>\n",
       "    train: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    test: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    valid: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDatasetDict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    train: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m450\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    test: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m25\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    valid: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m25\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = dataset['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "dataset['valid'] = test_data['train']\n",
    "dataset['test'] = test_data['test']\n",
    "del test_data\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa786730-1eb5-42e5-b567-1552b8df0131",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2TokenizerFast</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name_or_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'../models/nano-gpt-tokenizer'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">vocab_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">model_max_length</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">is_fast</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding_side</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'right'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">truncation_side</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'right'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">special_tokens</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bos_token'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'eos_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'unk_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">clean_up_tokenization_spaces</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,  </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">added_tokens_decoder</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AddedToken</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;|endoftext|&gt;\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">rstrip</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lstrip</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">single_word</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">normalized</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">special</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mGPT2TokenizerFast\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname_or_path\u001b[0m=\u001b[32m'../models/nano-gpt-tokenizer'\u001b[0m, \u001b[33mvocab_size\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mmodel_max_length\u001b[0m=\u001b[1;36m1024\u001b[0m, \n",
       "\u001b[33mis_fast\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mpadding_side\u001b[0m=\u001b[32m'right'\u001b[0m, \u001b[33mtruncation_side\u001b[0m=\u001b[32m'right'\u001b[0m, \u001b[33mspecial_tokens\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'bos_token'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|endoftext|\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[32m'eos_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|endoftext|>'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'unk_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|endoftext|>'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\u001b[33mclean_up_tokenization_spaces\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,  \u001b[0m\n",
       "\u001b[33madded_tokens_decoder\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mAddedToken\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m\"<|endoftext|\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m, \u001b[33mrstrip\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mlstrip\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33msingle_word\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mnormalized\u001b[0m=\u001b[3;92mTrue\u001b[0m, \n",
       "\u001b[33mspecial\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_pah)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa0d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f672f65bba0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a778a1f30ab042008720093a0d33eefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b64f20cd5146b5b044499cfcff96f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91648effa54f4a4fa65dd89a2f1e7013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetDict</span><span style=\"font-weight: bold\">({</span>\n",
       "    train: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    test: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    valid: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDatasetDict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    train: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m450\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    test: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m25\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    valid: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m25\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    outputs = tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "    )\n",
    "    return {'input_ids': outputs['input_ids']}\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset['train'].column_names\n",
    ")\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d571ca2a-7217-4584-a127-5bd5c6357f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'أصبحت فنلندا في 29 مارس 1809 دوقية ذاتية الحكم ضمن الإمبراطورية الروسية حتى عام 1917 بعد أن سيطرت عليها جيوش ألكسندر الأول في الحرب الفنلندية. ضم ألكسندر الأول في عام 1811 إقليم فيبورج الروسي إلى دوقية فنلندا. بدأت اللغة الفنلندية خلال الحقبة الروسية بالحصول على بعض الاعتراف. وابتداء من ستينيات القرن التاسع عشر ظهرت حركة وطنية فنلندية عرفت باسم حركة فينومن. كما نشرت الملحمة الفنلندية الوطنية «كاليفالا» في 1835 وحققت اللغة الفنلندية بذلك المساواة مع اللغة السويدية في عام 1892.\\nقتلت المجاعة التي ضربت فنلندا بين 1866-1868 نحو 15٪ من السكان، مما يجعلها واحدة من أسوأ المجاعات في التاريخ الأوروبي. دفعت المجاعة بالإمبراطورية الروسية لتخفيف القوانين المالية وزيادة الاستثمار في العقود التالية وانطلقت التنمية الاقتصادية والسياسية ونمت بسرعة. رغم ذلك كان نصيب الفرد من الناتج المحلي الإجمالي لا يزال نصف نظيره في الولايات المتحدة وثلث البريطاني.\\nفي عام 1906، اعتمد الاقتراع العام في دوقية فنلندا. مع ذلك، توترت العلاقة بين الدوقية والإمبراطورية الروسية عندما أقدمت الحكومة الروسية بخطوات لتقييد الحكم الفنلندي الذاتي. على سبيل المثال، كان الاقتراع العام عمليا غير ذي معنى حيث أن القيصر لم يوافق على أي من القوانين التي اعتمدها البرلمان الفنلندي. تطورت الرغبة في الاستقلال بداية بين الليبراليين المتطرفين  والاشتراكيين.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da8b565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT2Config <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_name_or_path\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"openai-community/gpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"activation_function\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu_new\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"GPT2LMHeadModel\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attn_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"bos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"embd_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"eos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"layer_norm_epsilon\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_ctx\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_embd\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_head\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_inner\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_layer\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_positions\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"reorder_and_upcast_attn\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"resid_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_by_inverse_layer_idx\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_weights\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_activation\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_first_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_proj_to_labels\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"cls_index\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_use_proj\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"task_specific_params\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"text-generation\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"do_sample\"</span>: true,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"max_length\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.45.2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"use_cache\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "GPT2Config \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"_name_or_path\"\u001b[0m: \u001b[32m\"openai-community/gpt2\"\u001b[0m,\n",
       "  \u001b[32m\"activation_function\"\u001b[0m: \u001b[32m\"gelu_new\"\u001b[0m,\n",
       "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"GPT2LMHeadModel\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"attn_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"bos_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"embd_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"eos_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"layer_norm_epsilon\"\u001b[0m: \u001b[1;36m1e-05\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"gpt2\"\u001b[0m,\n",
       "  \u001b[32m\"n_ctx\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"n_embd\"\u001b[0m: \u001b[1;36m256\u001b[0m,\n",
       "  \u001b[32m\"n_head\"\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "  \u001b[32m\"n_inner\"\u001b[0m: null,\n",
       "  \u001b[32m\"n_layer\"\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "  \u001b[32m\"n_positions\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"reorder_and_upcast_attn\"\u001b[0m: false,\n",
       "  \u001b[32m\"resid_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"scale_attn_by_inverse_layer_idx\"\u001b[0m: false,\n",
       "  \u001b[32m\"scale_attn_weights\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_activation\"\u001b[0m: null,\n",
       "  \u001b[32m\"summary_first_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"summary_proj_to_labels\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_type\"\u001b[0m: \u001b[32m\"cls_index\"\u001b[0m,\n",
       "  \u001b[32m\"summary_use_proj\"\u001b[0m: true,\n",
       "  \u001b[32m\"task_specific_params\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"text-generation\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"do_sample\"\u001b[0m: true,\n",
       "      \u001b[32m\"max_length\"\u001b[0m: \u001b[1;36m50\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.45.2\"\u001b[0m,\n",
       "  \u001b[32m\"use_cache\"\u001b[0m: true,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m8192\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(\n",
    "    model_ckpt, vocab_size=tokenizer.vocab_size,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    n_positions=tokenizer.model_max_length,\n",
    "    n_ctx=tokenizer.model_max_length,\n",
    "    n_embd=256, n_head=4, n_layer=4,\n",
    ")\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eed3687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2LMHeadModel</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Model</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>wte<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>wpe<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>h<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Block</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>ln_1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2SdpaAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>c_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attn_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>ln_2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2MLP</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>c_fc<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
       "          <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>ln_f<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mGPT2LMHeadModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Model\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m8192\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mwpe\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mh\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m4\u001b[0m x \u001b[1;35mGPT2Block\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mln_1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mGPT2SdpaAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mc_attn\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mattn_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mln_2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mGPT2MLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mc_fc\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m1024\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mln_f\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_config(model_config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118c13e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size in MBs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.269712</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size in MBs: \u001b[1;36m26.269712\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Size in MBs:', model.get_memory_footprint() / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b17f0838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Num Params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.518848</span> M\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Num Params: \u001b[1;36m5.518848\u001b[0m M\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Num Params:', model.num_parameters() / 1_000_000, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad20f59-f530-4057-9785-e9e2067b4bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "accum_steps = 1\n",
    "batch_size = 32\n",
    "total_steps = len(tokenized_dataset['train']) * \\\n",
    "    num_epochs // (batch_size * accum_steps)\n",
    "total_steps, batch_size * accum_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4163376e-e762-4a4a-8644-48daba9d3af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    run_name=RUN_NAME,\n",
    "    report_to='wandb',\n",
    "    save_strategy='no',\n",
    "    eval_strategy='steps',\n",
    "    gradient_accumulation_steps=accum_steps,\n",
    "    overwrite_output_dir=True,\n",
    "    data_seed=seed, seed=seed,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.0,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc6e7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07855904-d601-4b0d-bf42-2b813d580a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['valid'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a0f44af-1c94-4c29-aa6a-773e965ad1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aaaa3c3f7e407884c6ae473a307030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113362833323965, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/Projects/Arabic Nano GPT/notebooks/wandb/run-20241022_013313-dtgcm3ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT/runs/dtgcm3ge' target=\"_blank\">Overfitting-Small-Batch</a></strong> to <a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT' target=\"_blank\">https://wandb.ai/e_hossam96/Arabic-Nano-GPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT/runs/dtgcm3ge' target=\"_blank\">https://wandb.ai/e_hossam96/Arabic-Nano-GPT/runs/dtgcm3ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, job_type=JOB_TYPE,\n",
    "                 name=RUN_NAME, notes=NOTES, tags=TAGS, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94c36736-b019-4ca5-9d8c-46081eec35a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 04:31, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.472900</td>\n",
       "      <td>7.505480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.344400</td>\n",
       "      <td>7.068872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.941800</td>\n",
       "      <td>7.207415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.575200</td>\n",
       "      <td>7.677022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.416100</td>\n",
       "      <td>8.116169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.528500</td>\n",
       "      <td>8.450912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.899800</td>\n",
       "      <td>8.831320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.071157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>9.277331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>9.462207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>9.595050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>9.671283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>9.728360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>9.766155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>9.768268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56453b48-1ad7-41e8-b949-e501806057f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.5691556930542</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0575</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">434.502</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.38</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'epoch'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'test_loss'\u001b[0m: \u001b[1;36m9.5691556930542\u001b[0m,\n",
       "    \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m0.0575\u001b[0m,\n",
       "    \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m434.502\u001b[0m,\n",
       "    \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m17.38\u001b[0m,\n",
       "    \u001b[32m'epoch'\u001b[0m: \u001b[1;36m100.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainer.evaluate(tokenized_dataset['test'], metric_key_prefix='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a058ebb-56e8-4ee2-bd00-8befbd245446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▂▁▁▃▄▅▆▆▇▇█████</td></tr><tr><td>eval/runtime</td><td>▁▂▁▂▂▂▃▃▁▃▂▄▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▇▇▇▆▆█▆▇▅▇▆▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▇▇▇▆▆█▆▇▅▇▆▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▅▂▂█▂▂▆▁▁▅▁▁▄</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▆▅▅▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▄▃▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>9.76827</td></tr><tr><td>eval/runtime</td><td>0.0599</td></tr><tr><td>eval/samples_per_second</td><td>417.222</td></tr><tr><td>eval/steps_per_second</td><td>16.689</td></tr><tr><td>test/loss</td><td>9.56916</td></tr><tr><td>test/runtime</td><td>0.0575</td></tr><tr><td>test/samples_per_second</td><td>434.502</td></tr><tr><td>test/steps_per_second</td><td>17.38</td></tr><tr><td>total_flos</td><td>268756902273024.0</td></tr><tr><td>train/epoch</td><td>100</td></tr><tr><td>train/global_step</td><td>1500</td></tr><tr><td>train/grad_norm</td><td>3.16564</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.0846</td></tr><tr><td>train_loss</td><td>1.92509</td></tr><tr><td>train_runtime</td><td>272.4004</td></tr><tr><td>train_samples_per_second</td><td>165.198</td></tr><tr><td>train_steps_per_second</td><td>5.507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Overfitting-Small-Batch</strong> at: <a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT/runs/dtgcm3ge' target=\"_blank\">https://wandb.ai/e_hossam96/Arabic-Nano-GPT/runs/dtgcm3ge</a><br/> View project at: <a href='https://wandb.ai/e_hossam96/Arabic-Nano-GPT' target=\"_blank\">https://wandb.ai/e_hossam96/Arabic-Nano-GPT</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241022_013313-dtgcm3ge/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0275c80-4151-46ae-abf3-76224effb80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b54b2e7-6821-486c-b26b-86fec63b1e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _ = trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "065ce98d3aea499d8f00907d8cd5cb5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_47f6c5e6223a4af08bf2b7314a684053",
       "style": "IPY_MODEL_a9a6b6f452de4050b80c90b8d5d89301",
       "value": "Map: 100%"
      }
     },
     "134a0d3ab79a4bf7ac995de0181693c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18bd60b3efa54310995ae3a94ccd96b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "26f4826f29634ceeaca4ee4e42bbfd2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29332a6393f94e2f910aedf06a3faeb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "352fd1642425416cb748224e45ff0b57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a0614de114d94008b3a0fa3abab7c373",
       "max": 450,
       "style": "IPY_MODEL_67d010241cd34e298dac1f96881c9ec4",
       "value": 450
      }
     },
     "3a0e2f12e6e24510b0b9eeb18e7ec45e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_134a0d3ab79a4bf7ac995de0181693c6",
       "max": 1,
       "style": "IPY_MODEL_91e8b43977e74156bf5dc2d5fdda38ad",
       "value": 1
      }
     },
     "47f6c5e6223a4af08bf2b7314a684053": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "60988e4067d4441291f3067451e222a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_29332a6393f94e2f910aedf06a3faeb9",
       "style": "IPY_MODEL_df5e5206dff043cea4652688dacb199f",
       "value": "Waiting for wandb.init()...\r"
      }
     },
     "60b4bdb1158c4b3fb1f3d27879d6f032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6233518866ec45ee9ddbba9d107b2c0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67d010241cd34e298dac1f96881c9ec4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6dc6d80a34af4c27b852ee63593d480b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_be1f382706be499a9b92fdd89134818b",
       "style": "IPY_MODEL_e87e54003b034dbaa3ba0bd33a4f1561",
       "value": " 25/25 [00:00&lt;00:00, 2000.83 examples/s]"
      }
     },
     "6e22cb63919d49cc8d59eec9b670b1a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "787b35763c464cadb50cc96070313da3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_60b4bdb1158c4b3fb1f3d27879d6f032",
       "style": "IPY_MODEL_f9522d19ad25440c9e47b17c3b4abb99",
       "value": " 450/450 [00:00&lt;00:00, 6658.14 examples/s]"
      }
     },
     "812961e017364c209c85f4276d31f990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "91648effa54f4a4fa65dd89a2f1e7013": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f5e16520b4b44538841c7444ebcfc523",
        "IPY_MODEL_f7709f7479934b4f9bb0bee6d014edb2",
        "IPY_MODEL_eddb76650ef64d80bccee79dc963d2bc"
       ],
       "layout": "IPY_MODEL_6233518866ec45ee9ddbba9d107b2c0a"
      }
     },
     "91e8b43977e74156bf5dc2d5fdda38ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "94f118d4e20842b596241238ab8da483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_cc1a1489cd154b4ab84e0880531f37f2",
       "style": "IPY_MODEL_a793d36fb2b943358d06c9de8904531d",
       "value": "0.014 MB of 0.014 MB uploaded\r"
      }
     },
     "9a55b33475fb43e28eebd95fdcdab25c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9b70f4458d814a15bdd5c67e3be35899": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6e22cb63919d49cc8d59eec9b670b1a9",
       "max": 25,
       "style": "IPY_MODEL_a0682bd2b96b4c999d1a6ce886c151b4",
       "value": 25
      }
     },
     "9bb9babdc69d4e45ba551828af5ba2e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a0614de114d94008b3a0fa3abab7c373": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a0682bd2b96b4c999d1a6ce886c151b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a2075ebc5f034a80b0abec2823c8c17a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f00772b0adac43fe8018539511518a86",
       "style": "IPY_MODEL_a53c336e46bf40adbdd6a82e8673907b",
       "value": "Map: 100%"
      }
     },
     "a53c336e46bf40adbdd6a82e8673907b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a778a1f30ab042008720093a0d33eefa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_065ce98d3aea499d8f00907d8cd5cb5d",
        "IPY_MODEL_352fd1642425416cb748224e45ff0b57",
        "IPY_MODEL_787b35763c464cadb50cc96070313da3"
       ],
       "layout": "IPY_MODEL_26f4826f29634ceeaca4ee4e42bbfd2b"
      }
     },
     "a793d36fb2b943358d06c9de8904531d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "a8aaaa3c3f7e407884c6ae473a307030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_60988e4067d4441291f3067451e222a4",
        "IPY_MODEL_3a0e2f12e6e24510b0b9eeb18e7ec45e"
       ],
       "layout": "IPY_MODEL_b5f2038f3d2a4d40a3277e02c9a8adf6"
      }
     },
     "a9a6b6f452de4050b80c90b8d5d89301": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aef2ecc1148b4e1ba3ec94a68f4bc73a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b489aac894044714be427d76b754e608": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b5f2038f3d2a4d40a3277e02c9a8adf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "be1f382706be499a9b92fdd89134818b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0f9d9a7895e4578bd717925bf4b7aba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_c4be2c8e520a4e26ba606e0fbf19112d",
       "max": 1,
       "style": "IPY_MODEL_d8f187295cd445b9ab91922c546b5c4e",
       "value": 1
      }
     },
     "c2b64f20cd5146b5b044499cfcff96f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a2075ebc5f034a80b0abec2823c8c17a",
        "IPY_MODEL_9b70f4458d814a15bdd5c67e3be35899",
        "IPY_MODEL_6dc6d80a34af4c27b852ee63593d480b"
       ],
       "layout": "IPY_MODEL_aef2ecc1148b4e1ba3ec94a68f4bc73a"
      }
     },
     "c4be2c8e520a4e26ba606e0fbf19112d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc1a1489cd154b4ab84e0880531f37f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d3ec6b8e9ede44ad9d634709a77f6547": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8f187295cd445b9ab91922c546b5c4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dd10881a8d204b8ea3fa4c7f3160a080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "df5e5206dff043cea4652688dacb199f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "e87e54003b034dbaa3ba0bd33a4f1561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eddb76650ef64d80bccee79dc963d2bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_18bd60b3efa54310995ae3a94ccd96b9",
       "style": "IPY_MODEL_9bb9babdc69d4e45ba551828af5ba2e3",
       "value": " 25/25 [00:00&lt;00:00, 2142.40 examples/s]"
      }
     },
     "f00772b0adac43fe8018539511518a86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5e16520b4b44538841c7444ebcfc523": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9a55b33475fb43e28eebd95fdcdab25c",
       "style": "IPY_MODEL_812961e017364c209c85f4276d31f990",
       "value": "Map: 100%"
      }
     },
     "f7709f7479934b4f9bb0bee6d014edb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d3ec6b8e9ede44ad9d634709a77f6547",
       "max": 25,
       "style": "IPY_MODEL_dd10881a8d204b8ea3fa4c7f3160a080",
       "value": 25
      }
     },
     "f9522d19ad25440c9e47b17c3b4abb99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
