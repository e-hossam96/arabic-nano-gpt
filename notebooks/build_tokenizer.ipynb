{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Tokenizer\n",
    "\n",
    "In this notebook, we will create our gpt2-based tokenizer object to work with our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'openai-community/gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossam/miniconda3/envs/nanogpt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2TokenizerFast</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name_or_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai-community/gpt2'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">vocab_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #808000; text-decoration-color: #808000\">model_max_length</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">is_fast</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">padding_side</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'right'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">truncation_side</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'right'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">special_tokens</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bos_token'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'eos_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'unk_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|endoftext|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">clean_up_tokenization_spaces</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,  </span><span style=\"color: #808000; text-decoration-color: #808000\">added_tokens_decoder</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AddedToken</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;|endoftext|&gt;\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">rstrip</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lstrip</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">single_word</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">normalized</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">special</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mGPT2TokenizerFast\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname_or_path\u001b[0m=\u001b[32m'openai-community/gpt2'\u001b[0m, \u001b[33mvocab_size\u001b[0m=\u001b[1;36m50257\u001b[0m, \u001b[33mmodel_max_length\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mis_fast\u001b[0m=\u001b[3;92mTrue\u001b[0m, \n",
       "\u001b[33mpadding_side\u001b[0m=\u001b[32m'right'\u001b[0m, \u001b[33mtruncation_side\u001b[0m=\u001b[32m'right'\u001b[0m, \u001b[33mspecial_tokens\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'bos_token'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|endoftext|\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'eos_token'\u001b[0m\u001b[39m: \u001b[0m\n",
       "\u001b[32m'<|endoftext|>'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'unk_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|endoftext|>'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\u001b[33mclean_up_tokenization_spaces\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,  \u001b[0m\u001b[33madded_tokens_decoder\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;36m50256\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mAddedToken\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m\"<|endoftext|\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m, \u001b[33mrstrip\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mlstrip\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33msingle_word\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mnormalized\u001b[0m=\u001b[3;92mTrue\u001b[0m, \n",
       "\u001b[33mspecial\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sentences.txt', 'r') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">296603</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m296603\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">الماء مادة شفافة عديمة اللون والرائحة،\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "الماء مادة شفافة عديمة اللون والرائحة،\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = data[0]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§ÙĦ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ùħ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§Ø'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'¡'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠÙħ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§Ø'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'¯'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'´'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ù'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ģ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ù'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ģ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'¹'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø¯'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ÙĬ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ùħ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ§ÙĦ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ÙĦ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ÙĪ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ÙĨ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠÙĪ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§ÙĦ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø±'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§Ø'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'¦'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ń'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Į'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ċ'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Ø§ÙĦ'\u001b[0m,\n",
       "    \u001b[32m'Ùħ'\u001b[0m,\n",
       "    \u001b[32m'Ø§Ø'\u001b[0m,\n",
       "    \u001b[32m'¡'\u001b[0m,\n",
       "    \u001b[32m'ĠÙħ'\u001b[0m,\n",
       "    \u001b[32m'Ø§Ø'\u001b[0m,\n",
       "    \u001b[32m'¯'\u001b[0m,\n",
       "    \u001b[32m'Ø©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ'\u001b[0m,\n",
       "    \u001b[32m'´'\u001b[0m,\n",
       "    \u001b[32m'Ù'\u001b[0m,\n",
       "    \u001b[32m'ģ'\u001b[0m,\n",
       "    \u001b[32m'Ø§'\u001b[0m,\n",
       "    \u001b[32m'Ù'\u001b[0m,\n",
       "    \u001b[32m'ģ'\u001b[0m,\n",
       "    \u001b[32m'Ø©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ'\u001b[0m,\n",
       "    \u001b[32m'¹'\u001b[0m,\n",
       "    \u001b[32m'Ø¯'\u001b[0m,\n",
       "    \u001b[32m'ÙĬ'\u001b[0m,\n",
       "    \u001b[32m'Ùħ'\u001b[0m,\n",
       "    \u001b[32m'Ø©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ§ÙĦ'\u001b[0m,\n",
       "    \u001b[32m'ÙĦ'\u001b[0m,\n",
       "    \u001b[32m'ÙĪ'\u001b[0m,\n",
       "    \u001b[32m'ÙĨ'\u001b[0m,\n",
       "    \u001b[32m'ĠÙĪ'\u001b[0m,\n",
       "    \u001b[32m'Ø§ÙĦ'\u001b[0m,\n",
       "    \u001b[32m'Ø±'\u001b[0m,\n",
       "    \u001b[32m'Ø§Ø'\u001b[0m,\n",
       "    \u001b[32m'¦'\u001b[0m,\n",
       "    \u001b[32m'Ø'\u001b[0m,\n",
       "    \u001b[32m'Ń'\u001b[0m,\n",
       "    \u001b[32m'Ø©'\u001b[0m,\n",
       "    \u001b[32m'Ø'\u001b[0m,\n",
       "    \u001b[32m'Į'\u001b[0m,\n",
       "    \u001b[32m'Ċ'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenizer.tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_iterator(data: list[str], batch_size: int = 1_024):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i: i + batch_size]\n",
    "\n",
    "data_generator = get_data_iterator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossam/miniconda3/envs/nanogpt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_tokenizer = tokenizer.train_new_from_iterator(data_generator, vocab_size=4_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§ÙĦÙħ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§Ø¡'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠÙħØ§Ø¯Ø©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ´'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ùģ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§ÙģØ©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ¹'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø¯ÙĬ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ÙħØ©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠØ§ÙĦÙĦÙĪÙĨ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ĠÙĪØ§ÙĦØ±'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ø§Ø¦'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ØŃØ©'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ØĮ'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Ċ'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Ø§ÙĦÙħ'\u001b[0m,\n",
       "    \u001b[32m'Ø§Ø¡'\u001b[0m,\n",
       "    \u001b[32m'ĠÙħØ§Ø¯Ø©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ´'\u001b[0m,\n",
       "    \u001b[32m'Ùģ'\u001b[0m,\n",
       "    \u001b[32m'Ø§ÙģØ©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ¹'\u001b[0m,\n",
       "    \u001b[32m'Ø¯ÙĬ'\u001b[0m,\n",
       "    \u001b[32m'ÙħØ©'\u001b[0m,\n",
       "    \u001b[32m'ĠØ§ÙĦÙĦÙĪÙĨ'\u001b[0m,\n",
       "    \u001b[32m'ĠÙĪØ§ÙĦØ±'\u001b[0m,\n",
       "    \u001b[32m'Ø§Ø¦'\u001b[0m,\n",
       "    \u001b[32m'ØŃØ©'\u001b[0m,\n",
       "    \u001b[32m'ØĮ'\u001b[0m,\n",
       "    \u001b[32m'Ċ'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(new_tokenizer.tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/nano-gpt-tokenizer/tokenizer_config.json',\n",
       " '../models/nano-gpt-tokenizer/special_tokens_map.json',\n",
       " '../models/nano-gpt-tokenizer/vocab.json',\n",
       " '../models/nano-gpt-tokenizer/merges.txt',\n",
       " '../models/nano-gpt-tokenizer/added_tokens.json',\n",
       " '../models/nano-gpt-tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = new_tokenizer.save_pretrained('../models/nano-gpt-tokenizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
